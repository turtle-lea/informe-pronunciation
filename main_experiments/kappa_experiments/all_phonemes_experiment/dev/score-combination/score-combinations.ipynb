{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dir(dir_name):\n",
    "\ttry:\n",
    "\t\tos.makedirs(dir_name)\n",
    "\texcept OSError as exception:\n",
    "\t\tif exception.errno != errno.EEXIST:\n",
    "\t\t\traise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_positives_negatives_dict():\n",
    "    phonemes = [ \"Y\", \"f\", \"c\", \"x\", \"G\", \"d\", \"b\", \"g\", \"z\", \"w\", \"N\", \"B\", \"rr\", \"u\", \"p\", \"D\", \"y\", \"k\", \"m\", \"t\", \"l\", \"i\", \"r\", \"n\", \"s\", \"o\", \"a\", \"e\"]\n",
    "    positive_values = [ 53, 682, 405, 590, 222, 773, 528, 887, 189, 743, 911, 428, 491, 1948, 1657, 920, 2453, 1708, 3234, 2938, 3505, 4929, 3650, 7152, 7555, 8040, 10144, 10597]\n",
    "    negative_values = [10, 10, 105, 153, 643, 89, 395, 114, 997, 500, 443, 1169, 1739, 482, 1055, 2009, 574, 1472, 686, 1542, 1373, 1238, 2617, 476, 480, 2077, 2069, 3484 ]\n",
    "    total_values = [positive_values[i] + negative_values[i] for i in range(len(positive_values))]\n",
    "    total_instances = np.float(sum(total_values))\n",
    "    weighted_values = [v/total_instances for v in total_values]\n",
    "    positives_dict = dict(zip(phonemes, positive_values))\n",
    "    negatives_dict = dict(zip(phonemes, negative_values))\n",
    "    total_dict = dict(zip(phonemes, total_values))\n",
    "    weighted_dict = dict(zip(phonemes, weighted_values))\n",
    "    return (total_dict, weighted_dict, positives_dict, negatives_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factors = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "phonemes = [\n",
    "\t\"Y\", \"f\", \"c\", \"x\", \"G\", \"d\", \"b\", \"g\", \n",
    "\t\"z\", \"w\", \"N\", \"B\", \"rr\", \"u\", \"p\", \"D\", \n",
    "\t\"y\", \"k\", \"m\", \"t\", \"l\", \"i\", \"r\", \"n\", \n",
    "\t\"s\", \"o\", \"a\", \"e\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/lmatayoshi/Documents/Projects/tesis_notebooks/kappa_experiments/all_phonemes_experiment/features-combination/\"\n",
    "csvs_dir = base_dir + \"csvs/\"\n",
    "create_dir(csvs_dir)\n",
    "output_filename = csvs_dir + \"supervectors_dct_features_combination.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    factors_dict_dct = dict(zip(factors, [all_phonemes_empty_dict(all_phonemes) for f in factors]))\n",
    "    for factor in factors:\n",
    "        for phoneme in all_phonemes:\n",
    "            original_phoneme = phoneme\n",
    "            if phoneme in ['g', 'y', 'd', 'b', 'n']:\n",
    "                phoneme = phoneme + \"_lowercase\"\n",
    "            supervectors_filename = supervectors_dir + phoneme\n",
    "            dct_filename = dct_dir + phoneme\n",
    "            #output_file_dct = base_output_dir + phoneme\n",
    "\n",
    "            with open(supervectors_filename, \"r\") as f_supervectors:\n",
    "                lines_supervectors = f_supervectors.readlines()\n",
    "                lines_supervectors = [l.split(\" \") for l in lines_supervectors]\n",
    "            with open(dct_filename, \"r\") as f_dct:\n",
    "                lines_dct = f_dct.readlines()\n",
    "                lines_dct = [l.split(\" \") for l in lines_dct]\n",
    "        \n",
    "            check_logids(lines_supervectors, lines_dct)\n",
    "            \n",
    "            phoneme_values_dct = []\n",
    "            for i in range(len(lines_supervectors)):\n",
    "                new_value = float(lines_supervectors[i][4]) + factor*float(lines_dct[i][4])\n",
    "                new_line = lines_supervectors[i]\n",
    "                label = label_for(new_line[3])\n",
    "                new_tuple = (new_value, label)\n",
    "                new_line[4] = str(new_value)\n",
    "                new_line = \" \".join(new_line) + \"\\n\"\n",
    "                phoneme_values_dct.append(new_tuple)\n",
    "            factors_dict_dct[factor][original_phoneme] = compute_EER(phoneme_values_dct)\n",
    "    \n",
    "    return factors_dict_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "factors_dict_dct = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvs_dir = base_dir + \"csvs/\"\n",
    "create_dir(csvs_dir)\n",
    "csv_dct_filename = csvs_dir + \"dct_eers_by_factor.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataframe(factors_dict, output_filename):\n",
    "    original_phonemes_column = factors_dict[factors[0]].keys()\n",
    "    phonemes_column = np.array(original_phonemes_column).reshape(-1,1)\n",
    "    total_dict, weighted_dict, positives_dict, negatives_dict = load_positives_negatives_dict()\n",
    "    n_positives = np.array([positives_dict[phoneme] for phoneme in original_phonemes_column]).reshape(-1,1)\n",
    "    n_negatives = np.array([negatives_dict[phoneme] for phoneme in original_phonemes_column]).reshape(-1,1)\n",
    "    n_total = np.array([total_dict[phoneme] for phoneme in original_phonemes_column]).reshape(-1,1)\n",
    "    matrix = phonemes_column\n",
    "\n",
    "    for factor in factors:\n",
    "        factor_results = factors_dict[factor].values()\n",
    "        factor_results = np.array(factor_results).reshape(-1,1)\n",
    "        matrix = np.hstack((matrix, factor_results))\n",
    "    \n",
    "    min_indexes = []\n",
    "    # Find the best proportion by phoneme\n",
    "    for row in matrix:\n",
    "        min_index = np.argmin(np.array(row[1:].astype(np.float)))\n",
    "        min_indexes.append(factors[min_index])\n",
    "    min_indexes = np.array(min_indexes).reshape(-1,1)\n",
    "    \n",
    "    matrix = np.hstack((matrix, min_indexes))\n",
    "    matrix = np.hstack((matrix, n_positives))\n",
    "    matrix = np.hstack((matrix, n_negatives))\n",
    "    matrix = np.hstack((matrix, n_total))\n",
    "    \n",
    "    dataframe = pd.DataFrame(matrix[:, 1:], index=original_phonemes_column, columns=factors + ['best_factor','n_positives', 'n_negatives', 'n_total'])\n",
    "    dataframe = dataframe.astype(np.float)\n",
    "    dataframe = dataframe.sort_values(by=['n_total'])\n",
    "    dataframe.round(3).to_csv(path_or_buf=output_filename, index_label=\"Phonemes\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate_dataframe(factors_dict_legendre, csv_legendre_filename)\n",
    "dataframe = generate_dataframe(factors_dict_dct, csv_dct_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_phonemes_column = factors_dict_legendre[factors[0]].keys()\n",
    "phonemes_column = np.array(original_phonemes_column).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_dict, weighted_dict, positives_dict, negatives_dict = load_positives_negatives_dict()\n",
    "n_positives = np.array([positives_dict[phoneme] for phoneme in original_phonemes_column]).reshape(-1,1)\n",
    "n_negatives = np.array([negatives_dict[phoneme] for phoneme in original_phonemes_column]).reshape(-1,1)\n",
    "n_total = np.array([total_dict[phoneme] for phoneme in original_phonemes_column]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.7</th>\n",
       "      <th>1.0</th>\n",
       "      <th>n_positives</th>\n",
       "      <th>n_negatives</th>\n",
       "      <th>n_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.383562</td>\n",
       "      <td>0.383562</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>0.339806</td>\n",
       "      <td>53.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.439506</td>\n",
       "      <td>0.439506</td>\n",
       "      <td>0.441916</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>405.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.384164</td>\n",
       "      <td>0.360704</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>682.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.164407</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.156560</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>0.159322</td>\n",
       "      <td>590.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.363519</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.348315</td>\n",
       "      <td>0.351876</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>773.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.163297</td>\n",
       "      <td>0.167963</td>\n",
       "      <td>0.171171</td>\n",
       "      <td>0.178315</td>\n",
       "      <td>222.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.121519</td>\n",
       "      <td>0.123176</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>0.136536</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.145833</td>\n",
       "      <td>528.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.234470</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.252537</td>\n",
       "      <td>0.251409</td>\n",
       "      <td>887.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.217676</td>\n",
       "      <td>0.216931</td>\n",
       "      <td>0.219876</td>\n",
       "      <td>0.220662</td>\n",
       "      <td>0.217653</td>\n",
       "      <td>189.0</td>\n",
       "      <td>997.0</td>\n",
       "      <td>1186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0.150605</td>\n",
       "      <td>0.151247</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.153673</td>\n",
       "      <td>0.153432</td>\n",
       "      <td>0.152086</td>\n",
       "      <td>743.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.217344</td>\n",
       "      <td>0.209932</td>\n",
       "      <td>0.210757</td>\n",
       "      <td>0.212953</td>\n",
       "      <td>0.210487</td>\n",
       "      <td>0.206234</td>\n",
       "      <td>911.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1354.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.205607</td>\n",
       "      <td>0.203457</td>\n",
       "      <td>0.198598</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.199316</td>\n",
       "      <td>0.200935</td>\n",
       "      <td>428.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>1597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rr</th>\n",
       "      <td>0.321695</td>\n",
       "      <td>0.321792</td>\n",
       "      <td>0.325866</td>\n",
       "      <td>0.321792</td>\n",
       "      <td>0.315124</td>\n",
       "      <td>0.308223</td>\n",
       "      <td>491.0</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>2230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.353696</td>\n",
       "      <td>0.356229</td>\n",
       "      <td>0.354772</td>\n",
       "      <td>0.351643</td>\n",
       "      <td>0.348548</td>\n",
       "      <td>0.342402</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>2430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.294787</td>\n",
       "      <td>0.296069</td>\n",
       "      <td>0.296319</td>\n",
       "      <td>0.295992</td>\n",
       "      <td>0.298966</td>\n",
       "      <td>0.299725</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>2712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.181682</td>\n",
       "      <td>0.180222</td>\n",
       "      <td>0.183424</td>\n",
       "      <td>0.186957</td>\n",
       "      <td>0.187461</td>\n",
       "      <td>0.196739</td>\n",
       "      <td>920.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.337628</td>\n",
       "      <td>0.326947</td>\n",
       "      <td>0.313589</td>\n",
       "      <td>0.315124</td>\n",
       "      <td>0.311863</td>\n",
       "      <td>0.309359</td>\n",
       "      <td>2453.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>3027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.340749</td>\n",
       "      <td>0.333724</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.332201</td>\n",
       "      <td>0.328676</td>\n",
       "      <td>0.331382</td>\n",
       "      <td>1708.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>3180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.153989</td>\n",
       "      <td>0.154230</td>\n",
       "      <td>0.149660</td>\n",
       "      <td>0.148688</td>\n",
       "      <td>0.149969</td>\n",
       "      <td>0.151388</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>3920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.294423</td>\n",
       "      <td>0.292225</td>\n",
       "      <td>0.289653</td>\n",
       "      <td>0.287289</td>\n",
       "      <td>0.289235</td>\n",
       "      <td>0.289937</td>\n",
       "      <td>2938.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>4480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.279315</td>\n",
       "      <td>0.275489</td>\n",
       "      <td>0.272468</td>\n",
       "      <td>0.272337</td>\n",
       "      <td>0.272183</td>\n",
       "      <td>0.271723</td>\n",
       "      <td>3505.0</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>4878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.254443</td>\n",
       "      <td>0.252974</td>\n",
       "      <td>0.250355</td>\n",
       "      <td>0.249949</td>\n",
       "      <td>0.248788</td>\n",
       "      <td>0.249772</td>\n",
       "      <td>4929.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>6167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.317536</td>\n",
       "      <td>0.317675</td>\n",
       "      <td>0.311066</td>\n",
       "      <td>0.311043</td>\n",
       "      <td>0.310137</td>\n",
       "      <td>0.318082</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>2617.0</td>\n",
       "      <td>6267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.424370</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.421805</td>\n",
       "      <td>0.414150</td>\n",
       "      <td>0.414363</td>\n",
       "      <td>0.418345</td>\n",
       "      <td>7152.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>7628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.325444</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.310417</td>\n",
       "      <td>0.306949</td>\n",
       "      <td>0.304802</td>\n",
       "      <td>0.303492</td>\n",
       "      <td>7555.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>8035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.410204</td>\n",
       "      <td>0.407479</td>\n",
       "      <td>0.400069</td>\n",
       "      <td>0.398652</td>\n",
       "      <td>0.397886</td>\n",
       "      <td>0.397689</td>\n",
       "      <td>8040.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>10117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.353311</td>\n",
       "      <td>0.350407</td>\n",
       "      <td>0.346412</td>\n",
       "      <td>0.345094</td>\n",
       "      <td>0.345524</td>\n",
       "      <td>0.346188</td>\n",
       "      <td>10144.0</td>\n",
       "      <td>2069.0</td>\n",
       "      <td>12213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.399828</td>\n",
       "      <td>0.396433</td>\n",
       "      <td>0.392365</td>\n",
       "      <td>0.390356</td>\n",
       "      <td>0.388727</td>\n",
       "      <td>0.391094</td>\n",
       "      <td>10597.0</td>\n",
       "      <td>3484.0</td>\n",
       "      <td>14081.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0.0       0.1       0.3       0.5       0.7       1.0  n_positives  \\\n",
       "Y   0.383562  0.383562  0.400000  0.400000  0.396226  0.339806         53.0   \n",
       "c   0.439506  0.439506  0.441916  0.430556  0.429630  0.428571        405.0   \n",
       "f   0.384164  0.360704  0.334311  0.300000  0.300000  0.300000        682.0   \n",
       "x   0.164407  0.163399  0.156560  0.156863  0.158858  0.159322        590.0   \n",
       "d   0.363519  0.359551  0.348315  0.351876  0.359551  0.359551        773.0   \n",
       "G   0.162162  0.162162  0.163297  0.167963  0.171171  0.178315        222.0   \n",
       "b   0.121519  0.123176  0.126582  0.136536  0.136364  0.145833        528.0   \n",
       "g   0.234470  0.236842  0.228070  0.236842  0.252537  0.251409        887.0   \n",
       "z   0.222222  0.217676  0.216931  0.219876  0.220662  0.217653        189.0   \n",
       "w   0.150605  0.151247  0.154000  0.153673  0.153432  0.152086        743.0   \n",
       "N   0.217344  0.209932  0.210757  0.212953  0.210487  0.206234        911.0   \n",
       "B   0.205607  0.203457  0.198598  0.200000  0.199316  0.200935        428.0   \n",
       "rr  0.321695  0.321792  0.325866  0.321792  0.315124  0.308223        491.0   \n",
       "u   0.353696  0.356229  0.354772  0.351643  0.348548  0.342402       1948.0   \n",
       "p   0.294787  0.296069  0.296319  0.295992  0.298966  0.299725       1657.0   \n",
       "D   0.181682  0.180222  0.183424  0.186957  0.187461  0.196739        920.0   \n",
       "y   0.337628  0.326947  0.313589  0.315124  0.311863  0.309359       2453.0   \n",
       "k   0.340749  0.333724  0.329600  0.332201  0.328676  0.331382       1708.0   \n",
       "m   0.153989  0.154230  0.149660  0.148688  0.149969  0.151388       3234.0   \n",
       "t   0.294423  0.292225  0.289653  0.287289  0.289235  0.289937       2938.0   \n",
       "l   0.279315  0.275489  0.272468  0.272337  0.272183  0.271723       3505.0   \n",
       "i   0.254443  0.252974  0.250355  0.249949  0.248788  0.249772       4929.0   \n",
       "r   0.317536  0.317675  0.311066  0.311043  0.310137  0.318082       3650.0   \n",
       "n   0.424370  0.420168  0.421805  0.414150  0.414363  0.418345       7152.0   \n",
       "s   0.325444  0.316667  0.310417  0.306949  0.304802  0.303492       7555.0   \n",
       "o   0.410204  0.407479  0.400069  0.398652  0.397886  0.397689       8040.0   \n",
       "a   0.353311  0.350407  0.346412  0.345094  0.345524  0.346188      10144.0   \n",
       "e   0.399828  0.396433  0.392365  0.390356  0.388727  0.391094      10597.0   \n",
       "\n",
       "    n_negatives  n_total  \n",
       "Y          10.0     63.0  \n",
       "c         105.0    510.0  \n",
       "f          10.0    692.0  \n",
       "x         153.0    743.0  \n",
       "d          89.0    862.0  \n",
       "G         643.0    865.0  \n",
       "b         395.0    923.0  \n",
       "g         114.0   1001.0  \n",
       "z         997.0   1186.0  \n",
       "w         500.0   1243.0  \n",
       "N         443.0   1354.0  \n",
       "B        1169.0   1597.0  \n",
       "rr       1739.0   2230.0  \n",
       "u         482.0   2430.0  \n",
       "p        1055.0   2712.0  \n",
       "D        2009.0   2929.0  \n",
       "y         574.0   3027.0  \n",
       "k        1472.0   3180.0  \n",
       "m         686.0   3920.0  \n",
       "t        1542.0   4480.0  \n",
       "l        1373.0   4878.0  \n",
       "i        1238.0   6167.0  \n",
       "r        2617.0   6267.0  \n",
       "n         476.0   7628.0  \n",
       "s         480.0   8035.0  \n",
       "o        2077.0  10117.0  \n",
       "a        2069.0  12213.0  \n",
       "e        3484.0  14081.0  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = phonemes_column\n",
    "\n",
    "for factor in factors:\n",
    "    factor_results = factors_dict_legendre[factor].values()\n",
    "    factor_results = np.array(factor_results).reshape(-1,1)\n",
    "    matrix = np.hstack((matrix, factor_results))\n",
    "\n",
    "matrix = np.hstack((matrix, n_positives))\n",
    "matrix = np.hstack((matrix, n_negatives))\n",
    "matrix = np.hstack((matrix, n_total))\n",
    "\n",
    "dataframe = pd.DataFrame(matrix[:, 1:], index=original_phonemes_column, columns=factors + ['n_positives', 'n_negatives', 'n_total'])\n",
    "dataframe = dataframe.astype(np.float)\n",
    "dataframe = dataframe.sort_values(by=['n_total'])\n",
    "dataframe.round(3).to_csv(path_or_buf=csv_filename, index_label=\"Phonemes\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armar una matriz para el primer factor. Guardar en distintos CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key = factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = factors_dict_legendre[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_dict, weighted_dict, positives_dict, negatives_dict = load_positives_negatives_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_positives = np.array([positives_dict[phoneme] for phoneme in all_phonemes]).reshape(-1,1)\n",
    "n_negatives = np.array([negatives_dict[phoneme] for phoneme in all_phonemes]).reshape(-1,1)\n",
    "n_total = np.array([total_dict[phoneme] for phoneme in all_phonemes]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['rr', '0.321695412332', '53', '10', '63'],\n",
       "       ['B', '0.205607476635', '682', '10', '692'],\n",
       "       ['D', '0.181682429068', '405', '105', '510'],\n",
       "       ['G', '0.162162162162', '590', '153', '743'],\n",
       "       ['N', '0.217343578485', '222', '643', '865'],\n",
       "       ['Y', '0.383561643836', '773', '89', '862'],\n",
       "       ['a', '0.353310778153', '528', '395', '923'],\n",
       "       ['c', '0.43950617284', '887', '114', '1001'],\n",
       "       ['b', '0.121518987343', '189', '997', '1186'],\n",
       "       ['e', '0.399827784157', '743', '500', '1243'],\n",
       "       ['d', '0.363518758086', '911', '443', '1354'],\n",
       "       ['g', '0.234469873891', '428', '1169', '1597'],\n",
       "       ['f', '0.384164222874', '491', '1739', '2230'],\n",
       "       ['i', '0.254442649436', '1948', '482', '2430'],\n",
       "       ['k', '0.34074941452', '1657', '1055', '2712'],\n",
       "       ['m', '0.153988868275', '920', '2009', '2929'],\n",
       "       ['l', '0.279315263909', '2453', '574', '3027'],\n",
       "       ['o', '0.410203527815', '1708', '1472', '3180'],\n",
       "       ['n', '0.424369747898', '3234', '686', '3920'],\n",
       "       ['p', '0.294786729859', '2938', '1542', '4480'],\n",
       "       ['s', '0.325443786982', '3505', '1373', '4878'],\n",
       "       ['r', '0.317536301261', '4929', '1238', '6167'],\n",
       "       ['u', '0.353696098563', '3650', '2617', '6267'],\n",
       "       ['t', '0.294422827496', '7152', '476', '7628'],\n",
       "       ['w', '0.150604617076', '7555', '480', '8035'],\n",
       "       ['y', '0.337628014536', '8040', '2077', '10117'],\n",
       "       ['x', '0.164406779661', '10144', '2069', '12213'],\n",
       "       ['z', '0.222222222222', '10597', '3484', '14081']], \n",
       "      dtype='|S32')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes_column = np.array(actual.keys()).reshape(-1,1)\n",
    "results = np.array(actual.values()).reshape(-1,1)\n",
    "matrix = np.hstack((phonemes_column, results))\n",
    "matrix = np.hstack((matrix, n_positives))\n",
    "matrix = np.hstack((matrix, n_negatives))\n",
    "matrix = np.hstack((matrix, n_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3216954123315411,\n",
       " 0.20560747663513795,\n",
       " 0.1816824290679321,\n",
       " 0.16216216216220683,\n",
       " 0.21734357848518115,\n",
       " 0.3835616438356078,\n",
       " 0.35331077815300704,\n",
       " 0.4395061728395388,\n",
       " 0.1215189873431145,\n",
       " 0.39982778415655507,\n",
       " 0.3635187580855961,\n",
       " 0.23446987389070525,\n",
       " 0.38416422287390034,\n",
       " 0.25444264943604555,\n",
       " 0.3407494145199063,\n",
       " 0.15398886827481292,\n",
       " 0.2793152639086352,\n",
       " 0.41020352781546804,\n",
       " 0.4243697478981574,\n",
       " 0.29478672985874443,\n",
       " 0.3254437869822485,\n",
       " 0.31753630126056465,\n",
       " 0.35369609856259693,\n",
       " 0.2944228274956561,\n",
       " 0.1506046170758523,\n",
       " 0.3376280145358456,\n",
       " 0.1644067796610168,\n",
       " 0.2222222222222223]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rr', 'B', 'D', 'G', 'N', 'Y', 'a', 'c', 'b', 'e', 'd', 'g', 'f',\n",
       "       'i', 'k', 'm', 'l', 'o', 'n', 'p', 's', 'r', 'u', 't', 'w', 'y',\n",
       "       'x', 'z'], \n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(eer_degree_dir, csv_filename, plots_dir, weighted_average_dir, degree, alpha_values, alpha_values_str):\n",
    "    baselines_dicc = load_baselines()\n",
    "    results = []\n",
    "    \n",
    "    # Armo las distintas columnas para armar la matriz por degree\n",
    "    for alpha in alpha_values_str:\n",
    "        with open(eer_degree_dir + alpha, \"r\") as f:\n",
    "            result = f.read()\n",
    "        result = result.split(\"\\n\")\n",
    "        result = [l.split(\": \") for l in result]\n",
    "        result = [r for r in result if len(r) == 2]\n",
    "        if len(result) != 28:\n",
    "            raise Exception(\"Phonemes are not complete\")\n",
    "        results.append(result)\n",
    "    \n",
    "    total_dict, weighted_dict, positives_dict, negatives_dict = load_positives_negatives_dict()\n",
    "    base_matrix = np.array(results[0])\n",
    "    phonemes = base_matrix[:, 0]\n",
    "    n_positives = np.array([positives_dict[phoneme] for phoneme in phonemes]).reshape(-1,1)\n",
    "    n_negatives = np.array([negatives_dict[phoneme] for phoneme in phonemes]).reshape(-1,1)\n",
    "    n_total = np.array([total_dict[phoneme] for phoneme in phonemes]).reshape(-1,1)\n",
    "    \n",
    "    for i in range(1, len(results)):\n",
    "        new_column = np.array(results[i])[:, 1].reshape(-1,1)\n",
    "        base_matrix = np.hstack((base_matrix, new_column))\n",
    "    \n",
    "    ### PLOT WEIGHTED AVERAGES ###\n",
    "    # COMPUTE BASELINE FOR DEGREE\n",
    "    baseline = compute_weighted_average(baselines_dicc[degree][\"baseline_ols\"], weighted_dict)\n",
    "    weighted_averages = []\n",
    "    weighted_average_matrix = np.copy(base_matrix)\n",
    "    for i in range(weighted_average_matrix.shape[0]):\n",
    "        #weighted_average_matrix[i,1:] = weight_row(total_dict, weighted_average_matrix[i,0], weighted_average_matrix[i,1:])\n",
    "        weighted_average_matrix[i,1:] = weighted_average_matrix[i,1:].astype(np.float) * weighted_dict[weighted_average_matrix[i,0]]\n",
    "    for j in range(1, weighted_average_matrix.shape[1]):\n",
    "        eers = weighted_average_matrix[:,j].astype(np.float)\n",
    "        weighted_averages.append(np.sum(eers))\n",
    "    plt.clf()\n",
    "    min_index_weighted_averages = np.argmin(weighted_averages)\n",
    "    min_average = weighted_averages[min_index_weighted_averages]\n",
    "    min_alpha = alpha_values[min_index_weighted_averages]\n",
    "    title_weighted_averages = \"Grado \" + str(degree) + \". Min alpha: \" + str(min_alpha) + \", value: \" + str(min_average)\n",
    "    plt.plot(alpha_values, weighted_averages)\n",
    "    plt.axhline(y= baseline, linestyle=\"--\", color=\"black\")\n",
    "    plt.title(title_weighted_averages)\n",
    "    weighted_average_plot_filename = weighted_average_dir + \"weighted_average_plot\"\n",
    "    plt.savefig(weighted_average_plot_filename)\n",
    "    plt.clf()\n",
    "    \n",
    "    weighted_average_series = pd.Series(weighted_averages, index=alpha_values)\n",
    "    weighted_average_csv_filename = weighted_average_dir + \"weighted_average.csv\"\n",
    "    weighted_average_series.round(3).to_csv(path=weighted_average_csv_filename, index_label=\"Phonemes\")\n",
    "    ##############################\n",
    "\n",
    "    base_matrix = np.hstack((base_matrix, n_positives))\n",
    "    base_matrix = np.hstack((base_matrix, n_negatives))\n",
    "    base_matrix = np.hstack((base_matrix, n_total))\n",
    "    \n",
    "    dataframe = pd.DataFrame(base_matrix[:, 1:], index=phonemes, columns=alpha_values + ['n_positives', 'n_negatives', 'n_total'])\n",
    "    \n",
    "    for index, row in dataframe.iterrows():  \n",
    "        xs = row.index[:len(alpha_values)]\n",
    "        ys = np.array(row[:len(alpha_values)]).astype(np.float)\n",
    "        baseline_numpy = baselines_dicc[degree]['baseline_numpy_legendre'][index]\n",
    "        baseline = baselines_dicc[degree]['baseline_ols'][index]\n",
    "        plt.semilogx(xs, list(ys))\n",
    "        plt.axhline(y=baseline, linestyle=\"--\", color=\"black\")\n",
    "        delta = (np.min(ys) - baseline) / baseline\n",
    "        anotate(plt, xs, ys, delta, baseline)\n",
    "\n",
    "        title = \"Grado \" + str(degree) + \". Phoneme: \"+ index + \". Positives: \" + str(row[-2]) + \", Negatives: \" + str(row[-1])\n",
    "        plt.title(title)\n",
    "        if index in ['g', 'y', 'd', 'b', 'n']:\n",
    "            index = index + \"_lowercase\"\n",
    "        plot_filename = plots_dir + index\n",
    "        plt.savefig(plot_filename)\n",
    "        plt.clf()\n",
    "        \n",
    "    dataframe = dataframe.astype(np.float)\n",
    "    dataframe = dataframe.sort_values(by=['n_total'])\n",
    "    dataframe.round(3).to_csv(path_or_buf=csv_filename, index_label=\"Phonemes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
