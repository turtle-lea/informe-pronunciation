One of the main objectives of this work is to find out whether or not there is again in performance
when combining the supervectors features derived from \textit{GMM Adaptation} with features
that carry information of the evolution through time of the phonetic features.
The chosen approach to achieve that is to carry out a sample based study and analyse if the
finding generalizes to the parent population. A subset of the samples, the \textit{heldout} data,
is reserved with this purpose in order to test the models and generate statistics of its
performance. The statistic to be analysed in this case
is the \textit{EER} of the models
when tested against the heldout data, as it was mentioned in the previous \textit{Performance
Measures} section.

But how can be ensured that the sample based study generalizes to the parent population?
A summary statistic may fluctuate from sample set to sample set and it would be
desirable to somehow quantify the confidence regarding to the generalization of the
obtained statistics to the parent population.

In order to do so, two different techiques are used in this work: \textit{Bootstrapping} and \\
\textit{McNemar's Test}. They both focus on different aspects and thus allowing a
complementary analysis.

\subsection{Bootstrapping}

\cite{bootstrapping} \textit{Bootstrapping} is a general intuitive method applicable
to almost any kind of sample statistic and can be understood without much theoretical
knowledge of sampling distributions. It was introduced in 1979 by B. Efron and it has
been widely used in numerous areas since then.

Suppose it were possible to draw repeated samples
of the same size from the population of interest a large number of times. Then
a fairly good idea about the sampling distribution of a particular statistic from
the collection of its values arising from these repeated samples could be obtained.
This method doesn't make sense as it would be too expensive and defeat the purpose of a
sample study, that is gather information in the cheapest and effortless way.

The idea behind \textit{Bootstrapping} is to use the data of a sample study at hand as a
``surrogate population'' for the purpose of approximating the sampling distribution of
a statistic. This is achieved by resampling with replacement from the sample data
at hand and create a large number of alternative or duplicated sample sets known as
bootstrap samples. The sample summary is then computed on each of the bootstrap
samples (usually between 1-10 thousand). A histogram of the set of these computed
values is referred to as the bootstrap distribution of the statistic.

Suppose a population parameter $\theta$ is the target of the study. A random sample
of size $n$ yields the data $(X_{1}, X_{2}, \dotsc X_{n})$, and the corresponding
sample statistic computed from this dataset is ${\hat{\theta}}$.

\textit{Central Limit Theorem} states that for most sample
statistics the sampling distribution of ${\hat{\theta}}$ for large $n$
($n \geq 30$ is generally accepted as large sample size) is bell shaped with
center $\theta$ and standard deviation $a / \sqrt(n)$, where the positive number $a$
depends on the population and the type of statistic ${\hat{\theta}}$.
Often, there are serious technical complexities in approximating the required
standard deviation from the data. \textit{Bootstrapping} offers a bypass to this situation.
Let ${\hat{\theta}}_{B}$ stand for a random quantity which represents the same statistic
computed on a bootstrap sample drawn out of $(X_{1}, X_{2}, \dotsc X_{n})$.
In the limit as $n \to \infty$, the sampling distribution of ${\hat{\theta}}_{B}$
is also bell shaped with ${\hat{\theta}}$ as the center and the same standard deviation
$a / \sqrt(n)$. Then, bootstrap distribution of $\hat{\theta}_{B} - \hat{\theta}$
approximates fairy well the sampling distribution of $\hat{\theta} - \theta$.

It the current work, \textit{Bootstrapping} technique is used along with Confidence
Intervals in order to determine if the SVM trained with the combined features
performs better than the one trained with the supervectors features only.
Bootstrap samples are extracted from the \textit{heldout} data in order
to generate a distribution of $EER$ for both types of classifiers. After that,
a 95\% confidence interval is computed for each distribution by finding the interval
[$\hat{\theta}_{B1}, \hat{\theta}_{B2}$] that enclose the 95\% of the instances
composing each distribution. The bigger the overlap between both intervals, the
lesser the evidence of the results coming from different distributions and thus
resulting in less significant results.

