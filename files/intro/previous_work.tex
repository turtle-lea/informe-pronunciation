There are many works in the area of pronunciation assessment and describing all of them would
be a time consuming task. For that reason, only some of the works related to 
pronunciation assessment at phone level will be reviewed. \underline{Most of them are itended
for L2 language learners}

An initial approach
(\cite{pronunciation_scoring_instruction}\cite{pronunciation_scoring_phone_segments_instruction}) 
is based on \textit{Hidden Markov Models} (HMMs) to obtain 
spectral matches and compute pronunciation scores. Phonetic time alignments for
non-native utterances are generated from an HMM-based speech recognition system trained
with native instances as first step. To generate the alignments for the student's
speech the text read by the student must be known. This is achieved by eliciting speech in a
constrained way, such as reading a predifined text.
From these phonetic segmentations two 
probabilistic mesasures based on HMMs are computed as scores: log-likelihood and 
log-posterior probabilities. The underlying asumption is that the logarithm of the likelihood
of the speech data, computed by the Viterbi algorithm using the HMMs obtained from native
speakers is a good mesasure of the similarity between the native speech and the students's
speech.

For each phone segment the log-likelihood score \^{l} is computed as:
\begin{equation}
\hat{l} = \frac{1}{d} \sum_{t=t_{0}}^{t_{0}+d-1} log \ p(y_{t}|q_{i})
\end{equation}
where $p(y_{t}|q_{i})$ is the likelihood of the current frame with observation vector $y_{t}$
given the phone class $q_{i}$, $d$ is the duration in frames of the phone segment 
and $t_{0}$ is the starting frame index of the phone segment. Time normalization allows to 
eliminate the dependency of the pronunciation score on the duration of the phone.

Alternatively, in order to compute log-posterior scores, a frame-based posterior probability
$P(q_{i}|y_{t})$ is computed for each frame belonging to a segment.
\begin{equation}
P(q_{i}|y_{t}) = \frac{p(y_{t}|q_{i})P(q_{i})}{\sum\limits_{j=1}^{M} p(y_{t}|q_{j})P(q_{j})}
\end{equation}
Likelihood in the numerator is computed through a forced recognition phase by using a known 
ortographic transcription of the speech signal. On the other hand, 
the sum over $j$ runs over a set of context-independent models for all phone classes. $P(q_{i})$
represents the prior probability of the phone class $q_{i}$. 
%The speaker's speech is subjected to both a forced and a free speech recognition phase.
%During forced recognition a known orthographic transcription of the speech signal is used
%and in the free recognition phase the phoneme sequence most likely to be spoken is calculated.

Finally, the posterior score $\hat{\rho}$ for the phone segment is defined as:
\begin{equation}
\hat{\rho} = \frac{1}{d}\sum_{t=t_{0}}^{t_{0}+d-1} log \ P(q_{i}|y_{t})
\end{equation}

A very similar approach to log-posterior probabilities named \textit{Goodness of Pronunciation}
(GOP) is used in some works: \cite{gop_1} \cite{gop_2} \cite{gop_3}. The quality of 
pronunciation for any phone $p$ is defined to be the duration normalised log of the posterior
probability that the speaker uttered phone $p$ given the corresponding acoustic segment
$O^{(p)}$.

\begin{equation}
GOP(p) = \left| log \ \left(\frac{p(O^{(p)}|q)P(p))}{\sum_{q \in Q}p(O^{(p)}|q)P(q))}\right) \right| \Biggm/ NF(p)
\end{equation}

The difference between GOP scores and log-posterior score technique previously mentioned 
lies in that in GOP, likelihood for both numerator and every phone in the denominator is
computed at segment level as a sum of log-likelihood per frame over the 
duration of $O^{(p)}$, while in equation (1.2) log-posterior probabilities are computed
at the frame level and averaged over the segment's length.

A different technique is explored in \cite{detection_mispronunciation_instruction}, where
speech is modeled with networks of phone HMMs where each phone in the network can optionally
be pronounced either natively or not. Native phone models are initialized using a subset of
the native training speech data while nonnative models are initialized using the subset of 
the nonnative data that was scored low by the human raters. A mispronunciation score for each
sentence is then computed as a ratio between the number of nonnative phones to the total 
number of phones in the sentence.


So far, aforementioned methods are based on confidence measures obtained from HMM recognition. 
However, other types of classifiers are explored in many works, specially after
the 1990s. \textit{Support Vector Machines} (SVMs) are a preferred choice 
due to their excellent generalization capability and suitability for 2-class classification
problems. 
In \cite{detection_mispronunciation_dutch_vowel}, SVMs are trained with different types of
features to discriminate between good and mispronounced vowels in Dutch, including log-posteriors
obtained from HMMs, MFCCs and other phonetic features. 
On the other hand, features for \cite{svm_space_models} are based solely on
log-likelihood ratios between all the acoustic models and the model corresponding to the given
phone. It also introduces \textit{Pronunciation Space Models} (PSMs), 
built from an unsupervised method, where
each phone is modeled with several parallel acoustic models to represent pronunciation 
variations of that phone at different proficiency levels.
In \cite{landmark_svm}\cite{landmark_svm_2}, a landmark based 
SVM is introduced. Landmark theory relies on the fact that humans can perceive distinctive
features using only spectral features extracted from the time frame including and adjacent to
a landmark (sudden signal change). A particular SVM for each phoneme is trained. Vowel SVMs are 
trained using one or more frames from the vowel center. Frames from both onset and offset
(prevocalic and postvocalic position) are selected and used in the training of consonant
SVMs.

A different strategy for discrimination of Dutch velar fricative /x/ versus the velar plosive
/k/ is studied in \cite{lda_weigelt}. Latent Discriminant Analysis (LDA) over two different sets
of features are explored and compared with previous approaches: Aforementioned GOP scores and
Weigelt algorithm. The last one is based on three measures that can be easily obtained:
log root-mean-square (rms) energy, the derivative of log rms energy (\textit{Rate of Rise} or
ROR) and zero-crossing rate. Weigelt algorithm discriminate plosives from fricatives by using
ROR values, found on the fact that the release of the burst of the plosives causes an abrupt
rise in amplitude and therefore yielding higher values compared with fricatives.
In LDA weights are assigned to each features to find the linear combination of features
which best separates the classes. Selecting most relevant features turns out to be an
advantage compared to other classifiers.

A second group of papers are based on L1 strategies. A sufficiently large annotated nonnative
database is required in order to follow approaches of this kind.
In \cite{detection_phone_level_mispronunciation_learning}, a phonetically labeled nonnative
database is used to train two different \textit{Gaussian mixture models} (GMMs) for each phone
class: one model is trained with the "correct" native-like pronunciations of a phone, while the
other model is trained with the "mispronounced" or nonnative pronunciations of the same phone.
In the evaluation phase, for each phone segment $q_{i}$, a length-normalized log-likelihood ratio
$LLR(q_{i})$ score is computed for the phone segment by using the "mispronounced" and "correct"
pronunciation models $\lambda_{M}$ and $\lambda_{C}$ respectively:
\begin{equation}
LLR(q_{i}) = \frac{1}{d}\sum_{t=t_{0}}^{t_{0}+d-1} [log \ p(y_{t}|q_{i}, \lambda_{M}) - log \ p(y_{t}|q_{i}, \lambda_{C})]
\end{equation}
The normalization by $d$ allows definition of unique thresholds for the LLR for each phone class, 
independent of the length of the segments.

Finally, a recent work \cite{main} explores another method that also uses 
log-likelihood ratio based on  GMMs (equation 1.4), except that the models for each 
class ("correct" and  "mispronounced") are obtained by adaptation. In the same work, 
a discriminative system based
on \textit{Support Vector Machines} (SVM) is developed producing good results. Features 
for this classifier are obtained by adapting class-independent GMMs to each particular 
instance of the target phone and extracting both means and weights of the resulting 
Gaussian Mixture.
Both systems
previously described are used as baselines in the work here presented so a detailed explanation
will be provided in next sections.

%SVM-based classifier is built for each phone because the feature vectors are also phone-dependent.